{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
      ],
      "metadata": {
        "id": "PIHq9JsCxRvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Probability Mass Function (PMF) and Probability Density Function (PDF) are mathematical concepts used to describe the distribution of probabilities for discrete and continuous random variables, respectively.\n",
        "\n",
        "Probability Mass Function (PMF):\n",
        "\n",
        "The PMF gives the probability that a discrete random variable takes on a specific value.\n",
        "It's defined for discrete random variables and represented by a function\n",
        "�\n",
        "(\n",
        "�\n",
        "=\n",
        "�\n",
        ")\n",
        "P(X=x), where\n",
        "�\n",
        "X is the random variable and\n",
        "�\n",
        "x is a particular value the random variable can take.\n",
        "The sum of probabilities for all possible values of the random variable equals 1.\n",
        "Example: Consider rolling a fair six-sided die. The PMF for this scenario assigns a probability of\n",
        "1\n",
        "6\n",
        "6\n",
        "1\n",
        "​\n",
        "  to each possible outcome (1, 2, 3, 4, 5, or 6), as each outcome is equally likely.\n",
        "Probability Density Function (PDF):\n",
        "\n",
        "The PDF describes the probability distribution of a continuous random variable.\n",
        "It's represented by a function\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "f(x), where\n",
        "�\n",
        "x represents possible values of the continuous random variable.\n",
        "The area under the curve of the PDF over a certain range gives the probability of the random variable falling within that range.\n",
        "Unlike the PMF, the PDF itself doesn't directly provide probabilities for specific outcomes; rather, it gives the relative likelihood of different outcomes occurring.\n",
        "Example: The normal (Gaussian) distribution is a classic example of a continuous probability distribution with a PDF given by the formula\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "1\n",
        "2\n",
        "�\n",
        "�\n",
        "2\n",
        "�\n",
        "−\n",
        "(\n",
        "�\n",
        "−\n",
        "�\n",
        ")\n",
        "2\n",
        "2\n",
        "�\n",
        "2\n",
        "f(x)=\n",
        "2πσ\n",
        "2\n",
        "\n",
        "​\n",
        "\n",
        "1\n",
        "​\n",
        " e\n",
        "−\n",
        "2σ\n",
        "2\n",
        "\n",
        "(x−μ)\n",
        "2\n",
        "\n",
        "​\n",
        "\n",
        " , where\n",
        "�\n",
        "μ is the mean and\n",
        "�\n",
        "σ is the standard deviation. The PDF for the normal distribution describes the likelihood of the random variable taking on various values, with the highest likelihood (peak of the curve) being at the mean.\n",
        "In summary, PMF is used for discrete random variables, giving the probability of specific outcomes, while PDF is used for continuous random variables, describing the relative likelihood of different outcomes occurring over a continuous range of values."
      ],
      "metadata": {
        "id": "UxZ2asP_xRyf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
      ],
      "metadata": {
        "id": "QTJGy9wCxR1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Cumulative Density Function (CDF) is a concept in probability theory that describes the cumulative probability distribution of a random variable. It gives the probability that the random variable takes on a value less than or equal to a given point.\n",
        "\n",
        "Mathematically, for a random variable\n",
        "�\n",
        "X, the CDF is denoted as\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "F(x), and it's defined as:\n",
        "\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "�\n",
        "(\n",
        "�\n",
        "≤\n",
        "�\n",
        ")\n",
        "F(x)=P(X≤x)\n",
        "\n",
        "In simpler terms, the CDF at a particular point\n",
        "�\n",
        "x represents the probability that the random variable\n",
        "�\n",
        "X is less than or equal to\n",
        "�\n",
        "x.\n",
        "\n",
        "Example:\n",
        "Let's consider an example of rolling a fair six-sided die. Let\n",
        "�\n",
        "X be the random variable representing the outcome of rolling the die. The CDF\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "F(x) for this scenario can be expressed as follows:\n",
        "\n",
        "For\n",
        "�\n",
        "<\n",
        "1\n",
        "x<1,\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "0\n",
        "F(x)=0, because the die cannot show a value less than 1.\n",
        "For\n",
        "1\n",
        "≤\n",
        "�\n",
        "<\n",
        "2\n",
        "1≤x<2,\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "1\n",
        "6\n",
        "F(x)=\n",
        "6\n",
        "1\n",
        "​\n",
        " , because there is a\n",
        "1\n",
        "6\n",
        "6\n",
        "1\n",
        "​\n",
        "  probability of rolling a 1.\n",
        "For\n",
        "2\n",
        "≤\n",
        "�\n",
        "<\n",
        "3\n",
        "2≤x<3,\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "2\n",
        "6\n",
        "F(x)=\n",
        "6\n",
        "2\n",
        "​\n",
        " , because there is a\n",
        "2\n",
        "6\n",
        "6\n",
        "2\n",
        "​\n",
        "  probability of rolling a 1 or 2.\n",
        "And so on...\n",
        "The CDF accumulates probabilities as it moves along the possible values of the random variable, ultimately reaching a value of 1 when\n",
        "�\n",
        "x is greater than or equal to the maximum possible value of the random variable.\n",
        "\n",
        "Why CDF is used:\n",
        "The CDF is used for several reasons:\n",
        "\n",
        "Provides Cumulative Information: It gives a comprehensive view of the probability distribution of a random variable by providing the cumulative probabilities up to a given point.\n",
        "\n",
        "Calculating Probabilities: It allows for the easy calculation of probabilities for ranges of values of the random variable by taking differences in the CDF values.\n",
        "\n",
        "Characterizing Distributions: It helps in characterizing the shape and properties of probability distributions, aiding in statistical analysis and modeling.\n",
        "\n",
        "Comparison: CDFs can be used to compare different distributions and evaluate how they differ in terms of their cumulative probabilities.\n",
        "\n",
        "Overall, the CDF is a fundamental tool in probability theory and statistics for understanding the behavior of random variables and making probabilistic predictions."
      ],
      "metadata": {
        "id": "_fqXwkelxR4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
      ],
      "metadata": {
        "id": "xDHw3XQ2xR7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Normal Distribution, also known as the Gaussian Distribution, is one of the most important concepts in probability theory and statistics. Its significance lies in its wide range of applications across various fields, making it a fundamental tool for modeling and analyzing data. Here are some key reasons why the Normal Distribution is important:\n",
        "\n",
        "Central Limit Theorem (CLT): The Normal Distribution plays a central role in the Central Limit Theorem, which states that the distribution of the sum (or average) of a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the original distribution of the variables. This theorem has profound implications for statistical inference and hypothesis testing.\n",
        "\n",
        "Statistical Inference: Many statistical methods and techniques, such as hypothesis testing, confidence intervals, and regression analysis, rely on the assumption of normality. When data follow a normal distribution, these methods tend to be more accurate and reliable.\n",
        "\n",
        "Data Analysis: Normal distributions provide a convenient and mathematically tractable model for describing the distribution of continuous data in many real-world scenarios. This allows statisticians and data analysts to make predictions, draw conclusions, and perform various analyses with ease.\n",
        "\n",
        "Quality Control: In manufacturing and quality control processes, the Normal Distribution is often used to model the variability of product characteristics. By assuming that the process outputs follow a normal distribution, companies can set quality standards, detect deviations from these standards, and make informed decisions to improve product quality.\n",
        "\n",
        "Risk Management: In finance and investment, the Normal Distribution is commonly used to model the distribution of asset returns and risks. This allows investors and financial analysts to assess the probability of different outcomes and make informed decisions about portfolio management, risk mitigation, and investment strategies.\n",
        "\n",
        "Biological and Social Sciences: Many natural and social phenomena exhibit characteristics that can be approximated by a normal distribution. For example, human height, IQ scores, blood pressure measurements, and reaction times often follow a normal distribution. Understanding the normal distribution allows researchers to study and analyze these phenomena effectively.\n",
        "\n",
        "Real-life examples of Normal Distribution:\n",
        "\n",
        "Height of Individuals: The distribution of heights in a population often follows a normal distribution, with most people clustering around the mean height and fewer individuals at the extreme ends.\n",
        "\n",
        "IQ Scores: IQ scores of a large population tend to follow a normal distribution, with the majority of scores clustered around the mean IQ value and fewer individuals having exceptionally high or low scores.\n",
        "\n",
        "Exam Scores: In educational settings, exam scores are often normally distributed, with most students scoring around the average (mean) score and fewer students obtaining extremely high or low scores.\n",
        "\n",
        "Measurement Errors: Errors in measurement instruments, such as scales or thermometers, often follow a normal distribution, with most errors being small and fewer errors occurring at the extremes.\n",
        "\n",
        "Daily Temperatures: Daily temperatures in many regions tend to follow a normal distribution, with most days having temperatures near the average and fewer days experiencing extremely hot or cold temperatures."
      ],
      "metadata": {
        "id": "Ec09gjB_xR-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
      ],
      "metadata": {
        "id": "MyL-Hf_Y6ata"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bernoulli distribution is a discrete probability distribution that represents the outcome of a single Bernoulli trial, where there are only two possible outcomes: success or failure. It is named after the Swiss mathematician Jacob Bernoulli. The distribution is characterized by a single parameter, � p, which represents the probability of success.\n",
        "\n",
        "Probability Mass Function (PMF): The probability mass function of the Bernoulli distribution is:\n",
        "\n",
        "p & \\text{if } x = 1\n",
        "1 - p & \\text{if } x = 0 \\end{cases} ] where ( X ) is the random variable representing the outcome (1 for success, 0 for failure), and ( p ) is the probability of success. Example: Consider flipping a fair coin, where getting heads is considered a success (1) and getting tails is considered a failure (0). The outcome of each flip can be modeled using a Bernoulli distribution with ( p = 0.5 ), as the probability of getting heads or tails is equal. Difference between Bernoulli Distribution and Binomial Distribution:\n",
        "\n",
        "Number of Trials:\n",
        "Bernoulli Distribution: Represents the outcome of a single trial.\n",
        "Binomial Distribution: Represents the number of successes in a fixed number of independent Bernoulli trials.\n",
        "Random Variable:\n",
        "Bernoulli Distribution: Has a single random variable representing the outcome of a single trial (success or failure).\n",
        "Binomial Distribution: Has a random variable representing the number of successes in a fixed number of trials.\n",
        "Parameters:\n",
        "Bernoulli Distribution: Characterized by a single parameter ( p ), which is the probability of success in a single trial.\n",
        "Binomial Distribution: Characterized by two parameters: ( n ), the number of trials, and ( p ), the probability of success in each trial.\n",
        "Probability Mass Function (PMF):\n",
        "Bernoulli Distribution: The PMF gives the probability of success (1) or failure (0) in a single trial.\n",
        "Binomial Distribution: The PMF gives the probability of obtaining a specific number of successes in ( n ) trials.\n",
        "Outcome Range:\n",
        "Bernoulli Distribution: The random variable can take on only two values: 0 (failure) or 1 (success).\n",
        "Binomial Distribution: The random variable can take on values from 0 to ( n ), where ( n ) is the number of trials. In summary, the Bernoulli distribution models the outcome of a single trial, while the Binomial distribution models the number of successes in a fixed number of independent trials, each of which follows a Bernoulli distribution.\n"
      ],
      "metadata": {
        "id": "FM-PQHVJ6ap9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
      ],
      "metadata": {
        "id": "eCLxOIaj6anI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To calculate the probability that a randomly selected observation from a normally distributed dataset will be greater than 60, we need to use the properties of the standard normal distribution.\n",
        "\n",
        "First, we need to standardize the value 60 using the z-score formula:\n",
        "\n",
        "� = � − � � z= σ x−μ​\n",
        "\n",
        "Where:\n",
        "\n",
        "� x is the value we want to standardize (60 in this case), � μ is the mean of the distribution (50), � σ is the standard deviation of the distribution (10). Substituting the given values:\n",
        "\n",
        "� = 60 − 50 10 = 10 10 = 1 z= 10 60−50​= 10 10​=1\n",
        "\n",
        "Next, we find the probability corresponding to the standardized value of 1 using a standard normal distribution table or calculator. The probability of a value being greater than 60 is equal to 1 minus the cumulative probability up to � = 1 z=1.\n",
        "\n",
        "� ( �\n",
        "\n",
        "60 ) = 1 − � ( � ≤ 1 ) P(X>60)=1−P(Z≤1)\n",
        "\n",
        "Using a standard normal distribution table or calculator, we find � ( � ≤ 1 ) ≈ 0.8413 P(Z≤1)≈0.8413.\n",
        "\n",
        "Therefore,\n",
        "\n",
        "� ( �\n",
        "\n",
        "60 ) = 1 − 0.8413 = 0.1587 P(X>60)=1−0.8413=0.1587\n",
        "\n",
        "So, the probability that a randomly selected observation from the dataset will be greater than 60 is approximately 0.1587, or 15.87%."
      ],
      "metadata": {
        "id": "18J6scLX6yVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q7: Explain uniform Distribution with an example."
      ],
      "metadata": {
        "id": "Y7zHrkeB6yZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Uniform Distribution is a probability distribution where all outcomes are equally likely to occur within a given range. In other words, every value within the range has an equal probability of occurring. The probability density function (PDF) of a continuous uniform distribution is constant within the range and zero outside of it.\n",
        "\n",
        "Mathematically, if\n",
        "�\n",
        "X is a continuous random variable following a uniform distribution over the interval\n",
        "[\n",
        "�\n",
        ",\n",
        "�\n",
        "]\n",
        "[a,b], the PDF\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "f(x) is given by:\n",
        "\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "1\n",
        "�\n",
        "−\n",
        "�\n",
        " for\n",
        "�\n",
        "≤\n",
        "�\n",
        "≤\n",
        "�\n",
        "f(x)=\n",
        "b−a\n",
        "1\n",
        "​\n",
        "  for a≤x≤b\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "0\n",
        " for\n",
        "�\n",
        "<\n",
        "�\n",
        " or\n",
        "�\n",
        ">\n",
        "�\n",
        "f(x)=0 for x<a or x>b\n",
        "\n",
        "Example:\n",
        "Consider a simple example of rolling a fair six-sided die. The outcome of rolling the die follows a discrete uniform distribution because each face of the die (1, 2, 3, 4, 5, or 6) has an equal probability of\n",
        "1\n",
        "6\n",
        "6\n",
        "1\n",
        "​\n",
        "  of occurring.\n",
        "\n",
        "Now, let's take a continuous example. Suppose you have a spinner that can land anywhere between 0 and 100. The spinner follows a continuous uniform distribution because each value between 0 and 100 is equally likely to occur. In this case, the PDF of the uniform distribution is constant between 0 and 100 and is zero elsewhere:\n",
        "\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "1\n",
        "100\n",
        "−\n",
        "0\n",
        "=\n",
        "1\n",
        "100\n",
        " for\n",
        "0\n",
        "≤\n",
        "�\n",
        "≤\n",
        "100\n",
        "f(x)=\n",
        "100−0\n",
        "1\n",
        "​\n",
        " =\n",
        "100\n",
        "1\n",
        "​\n",
        "  for 0≤x≤100\n",
        "�\n",
        "(\n",
        "�\n",
        ")\n",
        "=\n",
        "0\n",
        " for\n",
        "�\n",
        "<\n",
        "0\n",
        " or\n",
        "�\n",
        ">\n",
        "100\n",
        "f(x)=0 for x<0 or x>100\n",
        "\n",
        "In summary, the uniform distribution describes situations where all outcomes within a given range are equally likely. It's a simple and intuitive distribution commonly used in various applications such as random number generation, simulations, and statistical modeling."
      ],
      "metadata": {
        "id": "Y39MgQkA7eqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q8: What is the z score? State the importance of the z score."
      ],
      "metadata": {
        "id": "atxBRsYr7r-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The z-score, also known as the standard score or standardization score, is a statistical measure that quantifies the number of standard deviations a data point is from the mean of a dataset. It indicates how many standard deviations an observation is above or below the mean of the dataset.\n",
        "\n",
        "Mathematically, the z-score of a data point\n",
        "�\n",
        "x is calculated using the formula:\n",
        "\n",
        "�\n",
        "=\n",
        "�\n",
        "−\n",
        "�\n",
        "�\n",
        "z=\n",
        "σ\n",
        "x−μ\n",
        "​\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "�\n",
        "x is the value of the data point,\n",
        "�\n",
        "μ is the mean of the dataset,\n",
        "�\n",
        "σ is the standard deviation of the dataset.\n",
        "The z-score can be positive, negative, or zero, depending on whether the data point is above, below, or equal to the mean, respectively. A positive z-score indicates that the data point is above the mean, while a negative z-score indicates that the data point is below the mean.\n",
        "\n",
        "Importance of the z-score:\n",
        "\n",
        "Standardization: The z-score standardizes data by converting different scales of measurement to a common scale, allowing for meaningful comparisons between different datasets. It helps in comparing data points from different distributions or variables that may have different units or scales.\n",
        "\n",
        "Identification of Outliers: Z-scores help identify outliers in a dataset by quantifying how far a data point deviates from the mean in terms of standard deviations. Data points with z-scores that are significantly higher or lower than a threshold value (e.g.,\n",
        "±\n",
        "3\n",
        "±3) may be considered outliers.\n",
        "\n",
        "Probability Calculation: Z-scores are used in probability calculations, particularly in the context of the standard normal distribution. They help determine the probability of observing a data point within a certain range or above/below a certain threshold by converting the data point to a standard normal distribution.\n",
        "\n",
        "Hypothesis Testing: Z-scores play a crucial role in hypothesis testing, particularly in comparing sample means to population means or testing the significance of a sample mean difference. They quantify the extent to which a sample mean differs from the population mean in terms of standard deviations."
      ],
      "metadata": {
        "id": "zSmVK_m27r61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
      ],
      "metadata": {
        "id": "cgDSweTU7r3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The Central Limit Theorem (CLT) is a fundamental theorem in probability theory and statistics that describes the behavior of the sample mean of a random variable, regardless of the underlying distribution of the variable. It states that, as the sample size increases, the distribution of the sample mean approaches a normal distribution, regardless of the shape of the original population distribution.\n",
        "\n",
        "Mathematically, the Central Limit Theorem can be stated as follows:\n",
        "\n",
        "Let\n",
        "�\n",
        "1\n",
        ",\n",
        "�\n",
        "2\n",
        ",\n",
        ".\n",
        ".\n",
        ".\n",
        ",\n",
        "�\n",
        "�\n",
        "X\n",
        "1\n",
        "​\n",
        " ,X\n",
        "2\n",
        "​\n",
        " ,...,X\n",
        "n\n",
        "​\n",
        "  be a sequence of independent and identically distributed (i.i.d.) random variables with mean\n",
        "�\n",
        "μ and standard deviation\n",
        "�\n",
        "σ. Then, as\n",
        "�\n",
        "n, the sample size, approaches infinity, the distribution of the sample mean\n",
        "�\n",
        "ˉ\n",
        "X\n",
        "ˉ\n",
        "  converges to a normal distribution with mean\n",
        "�\n",
        "μ and standard deviation\n",
        "�\n",
        "�\n",
        "n\n",
        "​\n",
        "\n",
        "σ\n",
        "​\n",
        " .\n",
        "\n",
        "In other words, regardless of the shape of the original population distribution, the sampling distribution of the sample mean becomes approximately normal as the sample size increases.\n",
        "\n",
        "Significance of the Central Limit Theorem:\n",
        "\n",
        "Sampling Distribution: The Central Limit Theorem provides a theoretical basis for understanding the behavior of sample means from random samples. It explains why the distribution of sample means tends to be normal, even when the underlying population distribution is not normal.\n",
        "\n",
        "Statistical Inference: The Central Limit Theorem forms the basis for many statistical techniques and methods, including hypothesis testing, confidence interval estimation, and regression analysis. It allows statisticians to make inferences about population parameters based on sample statistics, even when the population distribution is unknown or non-normal.\n",
        "\n",
        "Real-world Applications: The Central Limit Theorem has wide-ranging applications in various fields such as finance, economics, biology, engineering, and social sciences. It provides a theoretical framework for analyzing and interpreting data from random samples, making it a cornerstone of statistical analysis in practice.\n",
        "\n",
        "Quality Control: In quality control and manufacturing processes, the Central Limit Theorem is used to analyze and monitor the variability of product characteristics. It helps in setting quality standards, detecting deviations from these standards, and making informed decisions to improve product quality.\n",
        "\n",
        "Simulation Studies: The Central Limit Theorem is used in simulation studies to model complex systems and processes. By simulating random samples and applying the Central Limit Theorem, researchers can estimate probabilities and make predictions about the behavior of the system under different conditions.\n",
        "\n",
        "In summary, the Central Limit Theorem is a fundamental concept in statistics with broad applications in theory and practice. It provides valuable insights into the behavior of sample means and enables statisticians to make robust and reliable inferences about population parameters from random samples."
      ],
      "metadata": {
        "id": "5pOSTR837r0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q10: State the assumptions of the Central Limit Theorem."
      ],
      "metadata": {
        "id": "KcjEwkFP-Ye0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Central Limit Theorem (CLT) is a powerful theorem, but it relies on certain assumptions to hold true. These assumptions are essential for the CLT to accurately describe the behavior of sample means from random samples. The key assumptions of the Central Limit Theorem include:\n",
        "\n",
        "Independence: The observations in the sample must be independent of each other. In other words, the outcome of one observation should not influence the outcome of another observation. This assumption ensures that each observation provides unique information and that the sample is representative of the population.\n",
        "\n",
        "Identically Distributed: The random variables in the sample must be identically distributed. This means that each observation in the sample is drawn from the same population with the same probability distribution. If the observations are not identically distributed, the CLT may not accurately describe the behavior of the sample mean.\n",
        "\n",
        "Finite Variance: The population from which the sample is drawn must have a finite variance. This assumption ensures that the population distribution has a well-defined spread or variability. If the population variance is infinite or undefined, the CLT may not hold.\n",
        "\n",
        "Large Sample Size: The sample size must be sufficiently large. While there is no strict rule for what constitutes a \"large\" sample size, the CLT generally applies well when the sample size is greater than or equal to 30. Larger sample sizes tend to yield better approximations to the normal distribution.\n",
        "\n",
        "No Extreme Values: The population distribution should not contain extreme outliers or values that significantly deviate from the rest of the data. Extreme values can distort the behavior of the sample mean and violate the assumptions of the CLT.\n",
        "\n"
      ],
      "metadata": {
        "id": "Q7x175_o-YbQ"
      }
    }
  ]
}